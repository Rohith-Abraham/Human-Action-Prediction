{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'D:\\\\sk sir\\\\lab2\\\\human_action'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5148 images belonging to 9 classes.\n",
      "Found 1278 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the ImageDataGenerator with a validation split\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)  # Use 20% for testing/validation\n",
    "\n",
    "# Load training data (80%)\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(224, 224),  # Resize images\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Use 'binary' for binary classification\n",
    "    subset='training'  # Load the training data (80% of the images)\n",
    ")\n",
    "\n",
    "# Load validation data (20%)\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(224, 224),  # Resize images\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # Load the validation data (20% of the images)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 915ms/step - accuracy: 0.6222 - loss: 1.1560 - val_accuracy: 0.7066 - val_loss: 0.7725\n",
      "Epoch 2/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 1s/step - accuracy: 0.8122 - loss: 0.5284 - val_accuracy: 0.7856 - val_loss: 0.6531\n",
      "Epoch 3/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 416ms/step - accuracy: 0.8850 - loss: 0.3538 - val_accuracy: 0.7856 - val_loss: 0.6167\n",
      "Epoch 4/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 424ms/step - accuracy: 0.9098 - loss: 0.2699 - val_accuracy: 0.7973 - val_loss: 0.6323\n",
      "Epoch 5/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 607ms/step - accuracy: 0.9406 - loss: 0.1861 - val_accuracy: 0.7778 - val_loss: 0.7329\n",
      "Epoch 6/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 1s/step - accuracy: 0.9641 - loss: 0.1299 - val_accuracy: 0.7833 - val_loss: 0.7466\n",
      "Epoch 7/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 1s/step - accuracy: 0.9860 - loss: 0.0726 - val_accuracy: 0.8059 - val_loss: 0.7092\n",
      "Epoch 8/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 2s/step - accuracy: 0.9877 - loss: 0.0505 - val_accuracy: 0.7911 - val_loss: 0.7846\n",
      "Epoch 9/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 2s/step - accuracy: 0.9983 - loss: 0.0195 - val_accuracy: 0.8200 - val_loss: 0.7606\n",
      "Epoch 10/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.8232 - val_loss: 0.7984\n",
      "Epoch 11/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.8224 - val_loss: 0.8222\n",
      "Epoch 12/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 736ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.8271 - val_loss: 0.8300\n",
      "Epoch 13/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.8224 - val_loss: 0.8475\n",
      "Epoch 14/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 418ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.8208 - val_loss: 0.8593\n",
      "Epoch 15/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.8263 - val_loss: 0.8705\n",
      "Epoch 16/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.8247 - val_loss: 0.8852\n",
      "Epoch 17/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8239 - val_loss: 0.8935\n",
      "Epoch 18/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 790ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.8208 - val_loss: 0.8988\n",
      "Epoch 19/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 622ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.8247 - val_loss: 0.9135\n",
      "Epoch 20/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 645ms/step - accuracy: 1.0000 - loss: 8.3791e-04 - val_accuracy: 0.8247 - val_loss: 0.9189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x14f663ef310>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the pre-trained MobileNetV2 model without the top classification layers\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model's layers to prevent them from being updated during training\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom classification layers on top of the base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)\n",
    "\n",
    "# Create the full model by combining the base model and the new classification layers\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model with an optimizer, loss function, and metrics for evaluation\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the training data, using the test data for evaluation\n",
    "model.fit(train_generator, validation_data=validation_generator, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 320ms/step - accuracy: 0.8460 - loss: 0.7736\n",
      "Test Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print(f'Test Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
